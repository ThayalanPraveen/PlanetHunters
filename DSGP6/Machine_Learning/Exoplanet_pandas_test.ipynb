{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Import packages\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sklearn Packages\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Sklearn Evaluation Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error, precision_score, confusion_matrix, accuracy_score\n",
        "\n",
        "# Visualizes all the columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "array = joblib.load('Dataset.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['EC'] = df[1].apply(lambda x: 1 if x == 'CONFIRMED' else 1 if x == 'CANDIDATE' else 0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = df.drop(columns=[0,1,'EC'])\n",
        "target = df.EC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "medians=features.median(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_dict = features.to_dict(orient='index')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in range(0,len(df_dict)):\n",
        "    for y in range(2,53256):\n",
        "        df_dict[x][y] = df_dict[x][y] /medians[x] -1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum =0\n",
        "for x in range(0,len(df_dict)):\n",
        "    for y in range(2,53256):\n",
        "        if str(df_dict[x][y]) == \"nan\":\n",
        "            df_dict[x][y] = -999\n",
        "            sum = sum + 1\n",
        "        else:\n",
        "            df_dict[x][y] = float(df_dict[x][y])\n",
        "\n",
        "print(sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = pd.DataFrame.from_dict(df_dict,orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1, test_size=.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "\n",
        "def evaluation(y_true, y_pred):\n",
        "    \n",
        "# Print Accuracy, Recall, F1 Score, and Precision metrics.\n",
        "    print('Evaluation Metrics:')\n",
        "    print('Accuracy: ' + str(metrics.accuracy_score(y_test, y_pred)))\n",
        "    print('Recall: ' + str(metrics.recall_score(y_test, y_pred)))\n",
        "    print('F1 Score: ' + str(metrics.f1_score(y_test, y_pred)))\n",
        "    print('Precision: ' + str(metrics.precision_score(y_test, y_pred)))\n",
        "    \n",
        "# Print Confusion Matrix\n",
        "    print('\\nConfusion Matrix:')\n",
        "    print(' TN,  FP, FN, TP')\n",
        "    print(confusion_matrix(y_true, y_pred).ravel())\n",
        "    \n",
        "# Function Prints best parameters for GridSearchCV\n",
        "def print_results(results):\n",
        "    print('Best Parameters: {}\\n'.format(results.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Fitting Model to the train set\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "# Evaluating model\n",
        "evaluation(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tqdm.notebook import tqdm\n",
        "from time import sleep\n",
        "parameter_n_estimators = [500]\n",
        "for i in tqdm(parameter_n_estimators):\n",
        "    # Instantiate model\n",
        "    forest = RandomForestClassifier(n_estimators=i, criterion='gini')\n",
        "    # Fitting Model to the train set\n",
        "    forest.fit(X_train, y_train)\n",
        "    # Predicting on the test set\n",
        "    y_pred = forest.predict(X_test)\n",
        "\n",
        "    # Evaluating model\n",
        "    evaluation(y_test, y_pred)\n",
        "    print('Tree: %s ' % (i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightkurve as lk\n",
        "\n",
        "T_name = 'TIC 145241359'\n",
        "search_result = lk.search_lightcurve(T_name)\n",
        "data = []\n",
        "for x in range(0,17):\n",
        "    try:\n",
        "        lc = search_result[x].download() \n",
        "        y = lc.flux\n",
        "        for i in range(1,len(y),10):\n",
        "            try:\n",
        "                data.append(float(y[i].value))\n",
        "            except:\n",
        "                pass\n",
        "    except :\n",
        "        pass\n",
        "\n",
        "arr2 = pd.DataFrame(data)\n",
        "medians= arr2.median(axis=0)\n",
        "print(medians)\n",
        "arr3 =[]\n",
        "for x in range(0,53254):\n",
        "    try:\n",
        "        arr3.append((arr2[0][x] / medians)-1)\n",
        "    except:\n",
        "        arr3.append(-999)\n",
        "\n",
        "for x in range(0,53254):\n",
        "    temp = str(arr3[x])\n",
        "    if temp == 'nan' :\n",
        "        arr3[x] = -999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test1 = forest.predict([arr3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(test1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Exoplanet_ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

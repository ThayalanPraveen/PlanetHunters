{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Import packages\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sklearn Packages\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Sklearn Evaluation Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error, precision_score, confusion_matrix, accuracy_score\n",
        "\n",
        "# Visualizes all the columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "error",
          "evalue": "unpack requires a buffer of 8 bytes",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m/Users/thayalanpraveen/Documents/GitHub/PlanetHunters/DSGP6/Machine_Learning/Exoplanet_load_train.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thayalanpraveen/Documents/GitHub/PlanetHunters/DSGP6/Machine_Learning/Exoplanet_load_train.ipynb#ch0000001?line=0'>1</a>\u001b[0m array \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mDataset_test_bls.joblib\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=580'>581</a>\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=581'>582</a>\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=582'>583</a>\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=583'>584</a>\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=584'>585</a>\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=586'>587</a>\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=587'>588</a>\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
            "File \u001b[0;32m~/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=503'>504</a>\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=504'>505</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=505'>506</a>\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=506'>507</a>\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=507'>508</a>\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=508'>509</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=509'>510</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=510'>511</a>\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[1;32m    <a href='file:///Users/thayalanpraveen/Documents/Project_Interpreter/Env/lib/python3.9/site-packages/joblib/numpy_pickle.py?line=511'>512</a>\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.9/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/thayalanpraveen/miniforge3/lib/python3.9/pickle.py?line=1209'>1210</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/thayalanpraveen/miniforge3/lib/python3.9/pickle.py?line=1210'>1211</a>\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> <a href='file:///Users/thayalanpraveen/miniforge3/lib/python3.9/pickle.py?line=1211'>1212</a>\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   <a href='file:///Users/thayalanpraveen/miniforge3/lib/python3.9/pickle.py?line=1212'>1213</a>\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   <a href='file:///Users/thayalanpraveen/miniforge3/lib/python3.9/pickle.py?line=1213'>1214</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.9/pickle.py:1318\u001b[0m, in \u001b[0;36m_Unpickler.load_binfloat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/thayalanpraveen/miniforge3/lib/python3.9/pickle.py?line=1316'>1317</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_binfloat\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> <a href='file:///Users/thayalanpraveen/miniforge3/lib/python3.9/pickle.py?line=1317'>1318</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(unpack(\u001b[39m'\u001b[39;49m\u001b[39m>d\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39m8\u001b[39;49m))[\u001b[39m0\u001b[39m])\n",
            "\u001b[0;31merror\u001b[0m: unpack requires a buffer of 8 bytes"
          ]
        }
      ],
      "source": [
        "\n",
        "array = joblib.load('Dataset_test_bls.joblib')\n",
        "\n",
        "# if it does't work use the line below\n",
        "# array = joblib.load('Dataset1.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(array[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.fillna(-999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df.to_csv(\"Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_length = df.shape[1] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['EC'] = df[1].apply(lambda x: 1 if x == 'CONFIRMED' else 1 if x == 'CANDIDATE' else 0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = df.drop(columns=[0,1,'EC'])\n",
        "target = df.EC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1, test_size=.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "\n",
        "def evaluation(y_true, y_pred):\n",
        "    \n",
        "# Print Accuracy, Recall, F1 Score, and Precision metrics.\n",
        "    print('Evaluation Metrics:')\n",
        "    print('Accuracy: ' + str(metrics.accuracy_score(y_test, y_pred)))\n",
        "    print('Recall: ' + str(metrics.recall_score(y_test, y_pred)))\n",
        "    print('F1 Score: ' + str(metrics.f1_score(y_test, y_pred)))\n",
        "    print('Precision: ' + str(metrics.precision_score(y_test, y_pred)))\n",
        "    \n",
        "# Print Confusion Matrix\n",
        "    print('\\nConfusion Matrix:')\n",
        "    print(' TN,  FP, FN, TP')\n",
        "    print(confusion_matrix(y_true, y_pred).ravel())\n",
        "    \n",
        "# Function Prints best parameters for GridSearchCV\n",
        "def print_results(results):\n",
        "    print('Best Parameters: {}\\n'.format(results.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate model\n",
        "forest = RandomForestClassifier(bootstrap=False, max_depth=50, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=1000)\n",
        "# Fitting Model to the train set\n",
        "model = forest.fit(X_train, y_train)\n",
        "# Predicting on the test set\n",
        "y_pred = forest.predict(X_test)\n",
        "\n",
        "# Evaluating model\n",
        "evaluation(y_test,y_pred)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                     hidden_layer_sizes=(5,2), random_state=1)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "evaluation(y_test,y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(random_state = 42)\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"rf_random.best_params_\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightkurve as lk\n",
        "\n",
        "T_name = 'TIC 145241359'\n",
        "search_result = lk.search_lightcurve(T_name)\n",
        "data = []\n",
        "\n",
        "y = []\n",
        "lcs = lk.search_lightcurve(T_name).download_all()\n",
        "lc = lcs.stitch()\n",
        "lc_clean = lc.remove_outliers(sigma=20, sigma_upper=4)\n",
        "lc_clean = lc_clean.remove_nans()\n",
        "lc_clean = lc_clean.normalize()\n",
        "\n",
        "for x in range(0,len(lc_clean.flux),10):\n",
        "    try:\n",
        "        data.append(float(lc_clean.flux[x].value))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "arr2 = data\n",
        "for x in range(len(arr2),max_length-1):\n",
        "    arr2.append(-999)\n",
        "\n",
        "df = pd.DataFrame(arr2)\n",
        "df = df.fillna(-999)\n",
        "\n",
        "arr3 = []\n",
        "for x in df[0] :\n",
        "    arr3.append(x)\n",
        "\n",
        "for x in range(len(arr3),max_length-1):\n",
        "    arr3.append(-999)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = forest.predict([arr3])\n",
        "print(\"Random Forest\")\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#joblib.dump(forest,\"random_forest_model.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Exoplanet_ML.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "c389ce371d970bfbc3db3abccddfe5bee565366d23406449d68d8a0e44b07ec2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('Env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
